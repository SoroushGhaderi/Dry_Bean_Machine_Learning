{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Dry_Bean.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWtTxQKV1_Gp",
        "outputId": "9e27aa34-8db6-405d-bf76-15621ab07585"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlixUSTf1No9"
      },
      "source": [
        "import time\n",
        "import copy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "WNQU04mT1NpD",
        "outputId": "d39d2b3a-1408-4da2-fccd-6923057a7299"
      },
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/Dry_Bean/data/Dry_Bean_Dataset.xlsx\"\n",
        "dry_beans = pd.read_excel(DATA_PATH)\n",
        "dry_beans.head()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Area</th>\n",
              "      <th>Perimeter</th>\n",
              "      <th>MajorAxisLength</th>\n",
              "      <th>MinorAxisLength</th>\n",
              "      <th>AspectRation</th>\n",
              "      <th>Eccentricity</th>\n",
              "      <th>ConvexArea</th>\n",
              "      <th>EquivDiameter</th>\n",
              "      <th>Extent</th>\n",
              "      <th>Solidity</th>\n",
              "      <th>roundness</th>\n",
              "      <th>Compactness</th>\n",
              "      <th>ShapeFactor1</th>\n",
              "      <th>ShapeFactor2</th>\n",
              "      <th>ShapeFactor3</th>\n",
              "      <th>ShapeFactor4</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28395</td>\n",
              "      <td>610.291</td>\n",
              "      <td>208.178117</td>\n",
              "      <td>173.888747</td>\n",
              "      <td>1.197191</td>\n",
              "      <td>0.549812</td>\n",
              "      <td>28715</td>\n",
              "      <td>190.141097</td>\n",
              "      <td>0.763923</td>\n",
              "      <td>0.988856</td>\n",
              "      <td>0.958027</td>\n",
              "      <td>0.913358</td>\n",
              "      <td>0.007332</td>\n",
              "      <td>0.003147</td>\n",
              "      <td>0.834222</td>\n",
              "      <td>0.998724</td>\n",
              "      <td>SEKER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28734</td>\n",
              "      <td>638.018</td>\n",
              "      <td>200.524796</td>\n",
              "      <td>182.734419</td>\n",
              "      <td>1.097356</td>\n",
              "      <td>0.411785</td>\n",
              "      <td>29172</td>\n",
              "      <td>191.272750</td>\n",
              "      <td>0.783968</td>\n",
              "      <td>0.984986</td>\n",
              "      <td>0.887034</td>\n",
              "      <td>0.953861</td>\n",
              "      <td>0.006979</td>\n",
              "      <td>0.003564</td>\n",
              "      <td>0.909851</td>\n",
              "      <td>0.998430</td>\n",
              "      <td>SEKER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29380</td>\n",
              "      <td>624.110</td>\n",
              "      <td>212.826130</td>\n",
              "      <td>175.931143</td>\n",
              "      <td>1.209713</td>\n",
              "      <td>0.562727</td>\n",
              "      <td>29690</td>\n",
              "      <td>193.410904</td>\n",
              "      <td>0.778113</td>\n",
              "      <td>0.989559</td>\n",
              "      <td>0.947849</td>\n",
              "      <td>0.908774</td>\n",
              "      <td>0.007244</td>\n",
              "      <td>0.003048</td>\n",
              "      <td>0.825871</td>\n",
              "      <td>0.999066</td>\n",
              "      <td>SEKER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30008</td>\n",
              "      <td>645.884</td>\n",
              "      <td>210.557999</td>\n",
              "      <td>182.516516</td>\n",
              "      <td>1.153638</td>\n",
              "      <td>0.498616</td>\n",
              "      <td>30724</td>\n",
              "      <td>195.467062</td>\n",
              "      <td>0.782681</td>\n",
              "      <td>0.976696</td>\n",
              "      <td>0.903936</td>\n",
              "      <td>0.928329</td>\n",
              "      <td>0.007017</td>\n",
              "      <td>0.003215</td>\n",
              "      <td>0.861794</td>\n",
              "      <td>0.994199</td>\n",
              "      <td>SEKER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30140</td>\n",
              "      <td>620.134</td>\n",
              "      <td>201.847882</td>\n",
              "      <td>190.279279</td>\n",
              "      <td>1.060798</td>\n",
              "      <td>0.333680</td>\n",
              "      <td>30417</td>\n",
              "      <td>195.896503</td>\n",
              "      <td>0.773098</td>\n",
              "      <td>0.990893</td>\n",
              "      <td>0.984877</td>\n",
              "      <td>0.970516</td>\n",
              "      <td>0.006697</td>\n",
              "      <td>0.003665</td>\n",
              "      <td>0.941900</td>\n",
              "      <td>0.999166</td>\n",
              "      <td>SEKER</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Area  Perimeter  MajorAxisLength  ...  ShapeFactor3  ShapeFactor4  Class\n",
              "0  28395    610.291       208.178117  ...      0.834222      0.998724  SEKER\n",
              "1  28734    638.018       200.524796  ...      0.909851      0.998430  SEKER\n",
              "2  29380    624.110       212.826130  ...      0.825871      0.999066  SEKER\n",
              "3  30008    645.884       210.557999  ...      0.861794      0.994199  SEKER\n",
              "4  30140    620.134       201.847882  ...      0.941900      0.999166  SEKER\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qru6CveK3TKq"
      },
      "source": [
        "class DryBeanDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        data = pd.read_excel(path)\n",
        "        self.X = torch.Tensor(np.array(data.iloc[:, :-1], dtype=np.float32))\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.standard_scaler = StandardScaler()\n",
        "        self.y = torch.Tensor(self.label_encoder.fit_transform(data.iloc[:, -1]))\n",
        "        self.X = torch.Tensor(self.standard_scaler.fit_transform(self.X))\n",
        "        self.y_label_classes = self.label_encoder.classes_\n",
        "        self.n_samples = data.shape[0]\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        return self.X[item], self.y[item]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "    \n",
        "    def inverse_encoder(self):\n",
        "        return self.y_label_classes"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofbrAc0bEQBG"
      },
      "source": [
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(16,50)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(50, 7)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.fc1(x)\n",
        "        output = self.relu1(output)\n",
        "        output = self.fc2(output)\n",
        "        return output"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrahFDUj5_53"
      },
      "source": [
        "dry_bean = DryBeanDataset(DATA_PATH)"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rKwuXtAkNN3"
      },
      "source": [
        "X, y = dry_bean[:]"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of1FtD4f6_sC"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofT0a8JNtbf-",
        "outputId": "114f9240-5ce3-4a25-ef1b-1f70b3ceac67"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8175, -1.0217, -0.9929,  ...,  0.8773,  0.2669,  0.3482],\n",
              "        [-0.5101, -0.4671, -0.5726,  ...,  0.3294,  0.1658,  0.0537],\n",
              "        [-0.7530, -0.9509, -1.0500,  ...,  1.3828,  1.0176,  0.3483],\n",
              "        ...,\n",
              "        [ 1.2603,  1.4062,  1.5952,  ..., -1.2955, -0.9545, -0.2354],\n",
              "        [-0.4987, -0.6714, -0.8571,  ...,  1.4155,  1.6195,  0.8617],\n",
              "        [ 0.3608,  0.6632,  0.9411,  ..., -1.2211, -1.4065, -0.9976]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNF2Iu8Atgz3",
        "outputId": "4b312504-0634-4a1d-c491-648af707fc16"
      },
      "source": [
        "X_test"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3652, -0.5323, -0.6995,  ...,  1.1537,  1.5419,  0.9893],\n",
              "        [ 0.5183,  1.0895,  0.5861,  ..., -0.6254, -0.1022, -1.9952],\n",
              "        [-0.5181, -0.6840, -0.8369,  ...,  1.2638,  1.3878,  0.7263],\n",
              "        ...,\n",
              "        [-0.8402, -1.0839, -1.0833,  ...,  1.1801,  0.5712,  0.6621],\n",
              "        [ 0.7378,  0.8947,  0.9196,  ..., -0.9058, -0.4659, -0.5394],\n",
              "        [-0.4610, -0.5282, -0.4878,  ...,  0.1966,  0.0611,  0.4214]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7OUAwWWEEy_"
      },
      "source": [
        "train_data = TensorDataset(X_train, y_train.type(torch.LongTensor))\n",
        "test_data = TensorDataset(X_test, y_test.type(torch.LongTensor))"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vylABOby1Utl"
      },
      "source": [
        ""
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AZjfv8Dr1Lc"
      },
      "source": [
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "num_epoch = 20"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb6MOgDGn-p5"
      },
      "source": [
        "network = MLP()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = torch.optim.Adam(network.parameters(), lr=learning_rate)"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0wxMAlmoghA"
      },
      "source": [
        "data = {\"train\": train_data, \"val\": test_data}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(data[x], batch_size=batch_size, shuffle=True) for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(data[x]) for x in ['train', 'val']}\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmhZk5f937YD"
      },
      "source": [
        "def train_model(model, criterion, optimizer, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rr_sg6NoIzv",
        "outputId": "71f72814-e68b-4deb-9a3c-50d8e6620d1c"
      },
      "source": [
        "model_ft = train_model(network, criterion, optimizer_ft, num_epochs=num_epoch)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.4675 Acc: 0.8394\n",
            "val Loss: 0.2201 Acc: 0.9232\n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.2251 Acc: 0.9185\n",
            "val Loss: 0.2032 Acc: 0.9284\n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.2085 Acc: 0.9242\n",
            "val Loss: 0.1995 Acc: 0.9317\n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.2042 Acc: 0.9238\n",
            "val Loss: 0.2001 Acc: 0.9310\n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.2031 Acc: 0.9249\n",
            "val Loss: 0.2044 Acc: 0.9247\n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.1971 Acc: 0.9266\n",
            "val Loss: 0.2021 Acc: 0.9269\n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.1952 Acc: 0.9274\n",
            "val Loss: 0.2045 Acc: 0.9291\n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.1931 Acc: 0.9288\n",
            "val Loss: 0.1990 Acc: 0.9251\n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.1943 Acc: 0.9263\n",
            "val Loss: 0.2026 Acc: 0.9251\n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.1956 Acc: 0.9301\n",
            "val Loss: 0.2075 Acc: 0.9258\n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.1949 Acc: 0.9280\n",
            "val Loss: 0.1947 Acc: 0.9291\n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.1927 Acc: 0.9289\n",
            "val Loss: 0.1905 Acc: 0.9313\n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.1908 Acc: 0.9280\n",
            "val Loss: 0.1971 Acc: 0.9277\n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.1868 Acc: 0.9316\n",
            "val Loss: 0.2107 Acc: 0.9214\n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.1893 Acc: 0.9294\n",
            "val Loss: 0.2045 Acc: 0.9258\n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.1990 Acc: 0.9233\n",
            "val Loss: 0.1966 Acc: 0.9306\n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.1894 Acc: 0.9285\n",
            "val Loss: 0.1879 Acc: 0.9354\n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.1840 Acc: 0.9311\n",
            "val Loss: 0.2172 Acc: 0.9240\n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.1876 Acc: 0.9287\n",
            "val Loss: 0.2007 Acc: 0.9302\n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.1820 Acc: 0.9296\n",
            "val Loss: 0.1935 Acc: 0.9339\n",
            "\n",
            "Training complete in 0m 4s\n",
            "Best val Acc: 0.935365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuJcj-hTp9g-",
        "outputId": "d1e2c761-f1b6-4729-8318-a4b76349311a"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "random_forest = RandomForestClassifier()\n",
        "random_forest.fit(X_train, y_train)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSpJM-_yxuyg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84c95e7a-4276-4345-96f9-2f9aca9454dc"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_predict = random_forest.predict(X_test)\n",
        "accuracy_score(y_test, y_predict)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9250826294528094"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    }
  ]
}